{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "42a6d297-58df-4b79-b00d-8a91b3e65ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import textwrap\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166b822f-19f7-452d-8614-77d8221de572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'uri', 'duration_ms', 'time_signature', 'name', 'album_name',\n",
       "       'album_uri', 'artists'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_df = pd.read_csv('data/feat_df.csv')\n",
    "feat_df.columns\n",
    "# song_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebcff0-7f75-418d-88b8-01a7775bacd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vibes\n",
    "#  'danceability', 'energy', 'liveness', 'valence'\n",
    "\n",
    "# Music technicals\n",
    "#  -> Measure - continous\n",
    "#      'loudness', 'tempo'\n",
    "#  -> Measure - categorical\n",
    "#      'key', 'mode', 'time_signature'\n",
    "#  -> Instrumentality\n",
    "#      'speechiness', 'acousticness', 'instrumentalness'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd5d74-4a58-4f69-b61e-fbb0f654f7cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d7b69-3a3b-4895-aef0-4193759362e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 2, subplot_titles = ('danceability', 'energy', 'liveness', 'valence'), vertical_spacing = 0.1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = song_feats.danceability, name = 'daceability'), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.energy, name = 'energy'), row = 1, col = 2)\n",
    "fig.add_trace(go.Histogram(x = song_feats.liveness, name = 'liveness'), row = 2, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.valence, name = 'valence'), row = 2, col = 2)\n",
    "\n",
    "fig.update_layout(height = 850, width = 1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8f213-a2ac-45d8-b381-7c1a5959cc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 1, cols = 2, subplot_titles = ('loudness', 'tempo'), vertical_spacing = 0.1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = song_feats.loudness, name = 'loudness'), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.tempo, name = 'tempo'), row = 1, col = 2)\n",
    "\n",
    "fig.update_layout(height = 500, width = 1200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337bea3-ecd1-413f-a41a-f65d6639b6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 1, cols = 2, subplot_titles = ('key', 'mode'), vertical_spacing = 0.1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = song_feats.key, name = 'key'), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats['mode'], name = 'mode'), row = 1, col = 2)\n",
    "\n",
    "fig.update_layout(height = 500, width = 1200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07220adc-a566-49f8-a3cf-a17f05c6ad89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 3, cols = 1, subplot_titles = ('speechiness', 'acousticness', 'instrumentalness'), vertical_spacing = 0.1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = song_feats.speechiness, name = 'key'), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.acousticness, name = 'mode'), row = 2, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.instrumentalness, name = 'key'), row = 3, col = 1)\n",
    "\n",
    "fig.update_layout(height = 850, width = 600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26594956-d47d-4c92-9eff-0b8142389c90",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03080f91-90b6-46cf-b927-171322736751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vibes\n",
    "#  'danceability', 'energy', 'liveness', 'valence'\n",
    "\n",
    "# Music technicals\n",
    "#  -> Measure - continous\n",
    "#      'loudness', 'tempo'\n",
    "#  -> Measure - categorical\n",
    "#      'key', 'mode', 'time_signature'\n",
    "#  -> Instrumentality\n",
    "#      'speechiness', 'acousticness', 'instrumentalness'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abc22a-aa26-46f6-9c7b-6823376f295e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Genre Feature\n",
    "* Extract the artist_uris present on track and find matching genres from the artist_info data\n",
    "    * Don't really need to artist name because you just need unique ID to do the search and match\n",
    "* Possible feature: Primary artist\n",
    "    * The \"primary artist\" or main artist in tracks with multiple artists\n",
    "    * This is to possibly put heavier weights on the primary artist's genres as the featured artist should not affect the general vibe of the song as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c616eb-80c8-4320-bf41-6a91b0473d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artist_df = pd.read_csv('data/artist_info.csv')\n",
    "album_tracks = pd.read_csv('data/album_tracks.csv')\n",
    "album_df = pd.read_csv('data/album_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df672008-55cd-4810-8f29-b2627dbe17d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# artist_df['genres'].apply(ast.literal_eval)\n",
    "artist_df['genres'] = artist_df['genres'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36f38bba-de2c-40a5-8997-2424af76ddc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.65678858757019 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Get the artist_uris from\n",
    "\n",
    "def extract_artist_uris(artist_raw):\n",
    "    try:\n",
    "        artist_liteval = ast.literal_eval(artist_raw)\n",
    "        artist_list = [artist['uri'] for artist in artist_liteval]\n",
    "        return(artist_list)\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "feat_df['artists_clean'] = feat_df['artists'].apply(extract_artist_uris)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "6545ade5-2c66-4b17-907f-d4af2541bcde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_artist_name(artist_raw):\n",
    "    artist_liteval = ast.literal_eval(artist_raw.item())\n",
    "    artist_list = [artist['name'] for artist in artist_liteval]\n",
    "    return(artist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eee2943-bfa2-424a-ba7b-577515cac571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 95.94767260551453 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# getting the genres from artist into features\n",
    "\n",
    "def get_genres(uri_list):\n",
    "    try:\n",
    "        all_genres = []\n",
    "        for artist in uri_list:\n",
    "            genre_series = artist_df['genres'].loc[artist_df['artist_uri'] == artist]\n",
    "            for genre in genre_series:\n",
    "                all_genres.extend(genre)\n",
    "        return(all_genres)\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "feat_df['genres'] = feat_df['artists_clean'].apply(lambda x: get_genres(x))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac11875-9d06-4be1-90e2-2bc4a2f90e3c",
   "metadata": {},
   "source": [
    "## Feature Scaling and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f1a7f37-ae0c-4b14-ba73-94ec8422b28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating copy of dataframe\n",
    "feats_1 = feat_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fbd5957-8740-467b-a47c-baead4eaf375",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Scaling the song attribute measures\n",
    "scaled_vectors = min_max_scaler.fit_transform(feat_df[['loudness', 'tempo']])\n",
    "feats_1[['loudness_scaled', 'tempo_scaled']] = scaled_vectors\n",
    "\n",
    "# Scaling instrumentality features\n",
    "instr_vectors = min_max_scaler.fit_transform(feat_df[['speechiness', 'acousticness', 'instrumentalness']])\n",
    "feats_1[['speechiness_scaled', 'acousticness_scaled', 'instrumentalness_scaled']] = instr_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b5647d-790b-46ef-ba6e-c09339681996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the categorical data\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Song attributes\n",
    "feats_1 = pd.get_dummies(feats_1, columns = ['key', 'mode', 'time_signature'])\n",
    "feats_1.drop(columns = ['name', 'album_name', 'album_uri', 'artists', 'artists_clean'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687ad2d6-1a0c-4eba-9084-118b98e32616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vibes vector\n",
    "feats_1['vibe_vector'] = feats_1[['danceability', 'energy', 'valence', 'liveness']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32b861d4-cb89-4dcd-9a44-502e25fbb9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating genre matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_vectors = mlb.fit_transform(feats_1['genres'])\n",
    "genre_df = pd.DataFrame(genre_vectors, columns = mlb.classes_)\n",
    "genre_feat = pd.concat([feats_1.uri, genre_df], axis = 1)\n",
    "genre_feat = genre_feat.set_index('uri')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593fe23-0218-4988-baba-60569beace6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# V2: Cosine Similarity (sklearn implementation)\n",
    "* sklearn vs scipy vs creating your own with a function\n",
    "    * sklearn's is a vectorized function\n",
    "    * scipy seems to run it through a couple for loops (https://stackoverflow.com/questions/61490351/scipy-cosine-similarity-vs-sklearn-cosine-similarity)\n",
    "    * creating your own function then .apply() or something may be the only way if you need to do it in cloud computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d08c5f-3cf5-47c7-b913-58ce4623a7d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1ad1a-872a-4d01-b44f-ba2a5f6ebd5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Genre: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7a7c080-7aab-41be-93c4-70bcb68865f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10.000387191772461 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pca = PCA(n_components=100)  # Reduce to 100 dimensions, for example\n",
    "genre_feat_PCA = pd.DataFrame(pca.fit_transform(genre_feat), index = genre_feat.index)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# 10.69199252128601 seconds for a (178119 rows Ã— 1214 columns) matrix/dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4074017-58df-43bf-9f74-792fe7620134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100,000 -> N/A, needs 75 GB\n",
    "# 75,000 -> N/A, needs 41.9 GB\n",
    "# 50,000 -> 45.036359548568726 seconds -> 0.000900727190971 seconds per\n",
    "# 30,000 -> 16.268847942352295 seconds -> 0.000542294931412 seconds per\n",
    "# 25,000 -> 4.4220030307769775 seconds -> 0.000176880121231 seconds per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3554feef-9052-4b91-980b-e6b8522f8e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To be used on PCA reduced data\n",
    "# Using the genre feature to reduce the overall amount of songs used in cosine similarity\n",
    "#  When trying to find similarity, makes sense to reccomend like-genre songs like Rock to Rock or K-pop to K-pop\n",
    "\n",
    "def batch_cosine_genre(df, uri):\n",
    "    uri_slice = df.loc[df.index == uri]\n",
    "    df_other = df.loc[~(df.index == uri)]\n",
    "    \n",
    "    top_res = []\n",
    "    \n",
    "    batch_size = 14999\n",
    "    num_batches = len(df_other) // batch_size + (1 if len(df_other) % batch_size != 0 else 0)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_time = time.time()\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch = df_other[start:end]\n",
    "        batch = pd.concat([batch, uri_slice])\n",
    "        \n",
    "        batch_cs = cosine_similarity(batch)\n",
    "        batch_cs_df = pd.DataFrame(batch_cs, index = batch.index)\n",
    "        index_pos = batch_cs_df.index.get_loc(uri_slice.index[0])\n",
    "        batch_sim_scores = batch_cs_df.iloc[:, index_pos]\n",
    "        batch_top_1000 = batch_sim_scores.nlargest(1000).index\n",
    "        top_res.append(batch_top_1000)\n",
    "        print(f\"Batch {i} time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        # time.sleep(0.1)\n",
    "    \n",
    "    # Length of top_res is not actually (num_batches * 1000) because there are duplicated values of the uri_slice in each batch\n",
    "    #  so (num_batches * 1000) - (num_batches)\n",
    "    top_res_list = [item for sublist in top_res for item in sublist]\n",
    "    # top_res_select = df_other[df_other.index.isin(top_res_list)]\n",
    "    return(top_res_list)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "2ed19021-0d2f-4130-b5f4-e6b7f8df46c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Goes back to the feature dataframe and performs cosine\n",
    "def get_rec(df, tracks_df, uri, uri_list, top_n):\n",
    "    df_select = df[df.uri.isin(uri_list)]\n",
    "    df_select = df_select.set_index('uri')\n",
    "    df_select = df_select.drop(columns = ['genres', 'vibe_vector']) # ad hoc\n",
    "\n",
    "    if len(uri_list) < 15000:\n",
    "        cs_res = cosine_similarity(df_select)\n",
    "        cs_res = pd.DataFrame(cs_res, index = df_select.index)\n",
    "        recs_raw =  cs_res[cs_res.index.get_loc(uri)].nlargest(top_n).index.to_list()\n",
    "        \n",
    "        target_slice = tracks_df[tracks_df.uri == uri]\n",
    "        recs_df = tracks_df[tracks_df.uri.isin(recs_raw)]\n",
    "        \n",
    "        print(textwrap.dedent(f\"\"\"----- Original Song -----\n",
    "        Song: {target_slice.name.item()}\n",
    "        Album: {target_slice.album_name.item()} \n",
    "        Artist(s): {extract_artist_name(target_slice.artists)}\n",
    "        ---------------------------------------------\\n\"\"\"))\n",
    "        \n",
    "        for i in range(top_n):\n",
    "            print(textwrap.dedent(f\"\"\"----- Recommendation {i + 1} -----\n",
    "            Song: {recs_df.iloc[i]['name']}\n",
    "            Album: {recs_df.iloc[i]['album_name']}\n",
    "            Artist(s): {extract_artist_name(recs_df.iloc[i].artists)}\n",
    "            ---------------------------------------------\\n\"\"\"))\n",
    "    return(recs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "c7eaf045-d0c0-4419-ae1b-6c056f966d34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Original Song -----\n",
      "        Song: Dos Celulares\n",
      "        Album: Pisteando Con La Regida (Vol. 3) \n",
      "        Artist(s): ['Fuerza Regida']\n",
      "        ---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[437], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t2 \u001b[38;5;241m=\u001b[39m \u001b[43mget_rec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malbum_tracks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_rec_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m t2\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# slice = album_tracks[album_tracks.uri == test_uri]\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# test = extract_artist_name(slice.artists)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# test\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[435], line 25\u001b[0m, in \u001b[0;36mget_rec\u001b[1;34m(df, tracks_df, uri, uri_list, top_n)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m----- Original Song -----\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m    Song: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_slice\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m    Album: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_slice\u001b[38;5;241m.\u001b[39malbum_name\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m    Artist(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_artist_name(target_slice\u001b[38;5;241m.\u001b[39martists)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124m    ---------------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m))\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(top_n):\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m----- Recommendation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -----\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m        Song: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecs_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124m        Album: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecs_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malbum_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;124m        Artist(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mextract_artist_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecs_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martists\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m        ---------------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(recs_df)\n",
      "Cell \u001b[1;32mIn[409], line 2\u001b[0m, in \u001b[0;36mextract_artist_name\u001b[1;34m(artist_raw)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_artist_name\u001b[39m(artist_raw):\n\u001b[1;32m----> 2\u001b[0m     artist_liteval \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(\u001b[43martist_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m())\n\u001b[0;32m      3\u001b[0m     artist_list \u001b[38;5;241m=\u001b[39m [artist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m artist \u001b[38;5;129;01min\u001b[39;00m artist_liteval]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(artist_list)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "t2 = get_rec(feats_1, album_tracks, test_uri, test_rec_set, 10)\n",
    "t2\n",
    "\n",
    "        \n",
    "# slice = album_tracks[album_tracks.uri == test_uri]\n",
    "# test = extract_artist_name(slice.artists)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "94aa4228-84ff-4b14-9255-3679b745183f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_recs = get_rec(feats_1, test_uri, test_rec_set, 10)\n",
    "# test_recs\n",
    "\n",
    "t1 = feats_1[feats_1.uri.isin(test_rec_set)]\n",
    "t1 = t1.set_index('uri')\n",
    "t1 = t1.drop(columns = ['genres', 'vibe_vector'])\n",
    "t1_cs = cosine_similarity(t1)\n",
    "t1_cs_df = pd.DataFrame(t1_cs, index = t1.index)\n",
    "t_recs = t1_cs_df[t1_cs_df.index.get_loc(test_uri)].nlargest(50).index.to_list()\n",
    "t_recs += test_uri\n",
    "fin_recs = album_tracks[album_tracks.uri.isin(t_recs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94f605e1-6e03-44db-a353-ec9224508d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 time: --- 1.1830744743347168 seconds ---\n",
      "Batch 1 time: --- 1.3191990852355957 seconds ---\n",
      "Batch 2 time: --- 1.337620735168457 seconds ---\n",
      "Batch 3 time: --- 1.3658716678619385 seconds ---\n",
      "Batch 4 time: --- 1.302027702331543 seconds ---\n",
      "Batch 5 time: --- 1.3494820594787598 seconds ---\n",
      "Batch 6 time: --- 0.633575439453125 seconds ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'spotify:track:54FL6e96e4hOh5JT47kC4A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m test_rec_set \u001b[38;5;241m=\u001b[39m batch_cosine_genre(func_test_set, test_uri)\n\u001b[1;32m----> 9\u001b[0m test_recs \u001b[38;5;241m=\u001b[39m \u001b[43mget_rec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_rec_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "Cell \u001b[1;32mIn[71], line 6\u001b[0m, in \u001b[0;36mget_rec\u001b[1;34m(df, uri, uri_list, top_n)\u001b[0m\n\u001b[0;32m      3\u001b[0m df_select \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39muri\u001b[38;5;241m.\u001b[39misin(uri_list)]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uri_list) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m15000\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     cs_res \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     cs_res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(cs_res, index \u001b[38;5;241m=\u001b[39m df_select\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m      8\u001b[0m     recs \u001b[38;5;241m=\u001b[39m  cs_res[cs_res\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(uri)]\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1668\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \n\u001b[0;32m   1626\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1668\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1670\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:164\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[0;32m    161\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype_float\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    175\u001b[0m         X,\n\u001b[0;32m    176\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    182\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\sklearn\\utils\\validation.py:1007\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1007\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1011\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\sklearn\\utils\\_array_api.py:746\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    744\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'spotify:track:54FL6e96e4hOh5JT47kC4A'"
     ]
    }
   ],
   "source": [
    "func_test_set = genre_feat_PCA[:100000]\n",
    "\n",
    "test_uri = 'spotify:track:75ZkrYWgQtQjRdpsubetpG'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_rec_set = batch_cosine_genre(func_test_set, test_uri)\n",
    "\n",
    "test_recs = get_rec(feats_1, test_uri, test_rec_set, 10)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2fab1cf1-fc50-4535-991b-6438b0ce861b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23b16c2b-f5d8-48fc-b8d4-5316455c7759",
   "metadata": {
    "tags": []
   },
   "source": [
    "# (Deprecated) V1: AWS, Spark, and DIMSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844be12-c7ae-4f71-9440-e89fdda7887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Credentials and Settings\n",
    "access_key = 'ACCESS_KEY'\n",
    "secret_key = 'SECRET_ACCESS_KEY'\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = access_key\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = secret_key\n",
    "encoded_secret_key = secret_key.replace(\"/\", \"%2F\").replace(\"+\", \"%2B\")\n",
    "\n",
    "aws_region = 'us-east-1'\n",
    "\n",
    "s3 = boto3.client(\n",
    "    service_name='s3',\n",
    "    region_name=aws_region,\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86126180-1dc8-44b4-ad30-930095e77026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession, Row, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf, explode, col, collect_list, regexp_replace, split, expr, length, concat_ws, count, size, first, broadcast, monotonically_increasing_id\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType, FloatType, DoubleType\n",
    "from pyspark import sql\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Set up Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PicklesPlus\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\",\"s3.\" + aws_region + \".amazonaws.com\") \\\n",
    "    .config(\"spark.executor.memory\", \"15g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.default.parallelism\", \"4\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a90c2b-fd72-401d-a5f6-a267aa065912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ML libraries\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "from pyspark.ml.stat import Correlation, ChiSquareTest, Summarizer\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, Tokenizer, HashingTF, IDF, VectorAssembler, StandardScaler, OneHotEncoder, Normalizer, StopWordsRemover, CountVectorizer\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors, VectorUDT\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7940b-6cbc-428f-9a72-de7c2c64482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = spark.read.parquet('s3a://kagglespotify6k/raw/main_dataset.parquet/')\n",
    "\n",
    "all_tracks = spark.read.parquet('s3a://kagglespotify6k/trusted/all_tracks/')\n",
    "\n",
    "\n",
    "# main contains some duplicate columns\n",
    "columns_to_drop = ['key', 'loudness', 'mode', 'tempo', 'time_signature']\n",
    "main_merge = main.drop(*columns_to_drop)\n",
    "\n",
    "# Join the 2 dataframes\n",
    "merged_df = all_tracks.join(main_merge, all_tracks['track_uri'] == main_merge['track_uri'])\n",
    "merged_df = merged_df.drop(main_merge['track_uri'])\n",
    "merged_df = merged_df.withColumn('playlist_uris', expr(\"substring(split(playlist_uris, ':')[2], 1, length(split(playlist_uris, ':')[2]) - 2)\"))\n",
    "merged_df = merged_df.withColumn('playlist_uris_list', split('playlist_uris', ',\\s'))\n",
    "\n",
    "merged_df.write.mode('overwrite').parquet('s3a://kagglespotify6k/trusted/merged_main_tracks_all/')\n",
    "\n",
    "# 28.79 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea3b99-c95a-4d01-ab92-1f9d7377d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df2 = spark.read.parquet('s3a://kagglespotify6k/trusted/feature_df_all270k/')\n",
    "\n",
    "# Aggregating the categorical features to avoid having to one hot encode with a for loop\n",
    "feat_df2 = feat_df2.withColumn('categorical', F.array(col('key'),col('mode'), col('time_signature')))\n",
    "feat_test = feat_df2.limit(900)\n",
    "## First, vectorize the textual categorical features (genre and playlists) into genre_vec\n",
    "\n",
    "# artists_genres & playlist_uris_list already tokenized -> [genre_a, genre_b, genre_c], skip straight to hashing\n",
    "hashingTF_genres = HashingTF(numFeatures = 50, inputCol = 'artists_genres', outputCol = 'genre_hash')\n",
    "idf_genres = IDF(inputCol = 'genre_hash', outputCol = 'genre_idf')\n",
    "\n",
    "hashingTF_playlists = HashingTF(numFeatures = 50, inputCol = 'playlist_uris_list', outputCol = 'playlist_hash')\n",
    "idf_playlists = IDF(inputCol = 'playlist_hash', outputCol = 'playlist_idf')\n",
    "\n",
    "## Vectorizing the music technique categorical features (key, mode, time_signature)\n",
    "# Referenced: https://stackoverflow.com/questions/35804755/apply-onehotencoder-for-several-categorical-columns-in-sparkmlib\n",
    "#   StringIndexer only takes in 1 column at a time\n",
    "hashingTF_categ = HashingTF(numFeatures = 50, inputCol = 'categorical', outputCol = 'categ_hash')\n",
    "idf_categ = IDF(inputCol = 'categ_hash', outputCol = 'categ_idf')\n",
    "\n",
    "## Vectorizing the confidence measure features (they are on a scale of 0 - 1.0)\n",
    "conf_VecAssembler = VectorAssembler(inputCols = ['acousticness', 'instrumentalness', 'speechiness', 'valence', 'danceability', 'energy', 'liveness'], outputCol = 'conf_features')\n",
    "# conf_scaler = StandardScaler(inputCol = 'conf_features', outputCol = 'scaled_conf_features')\n",
    "\n",
    "## Final feature vector\n",
    "final_VecAssembler = VectorAssembler(inputCols=['genre_idf', 'playlist_idf', 'categ_idf', 'conf_features'], outputCol='features')\n",
    "\n",
    "## Pipeline\n",
    "pipeline = Pipeline(stages = [hashingTF_genres, idf_genres, hashingTF_playlists, idf_playlists , hashingTF_categ, idf_categ, conf_VecAssembler, final_VecAssembler])\n",
    "\n",
    "model = pipeline.fit(feat_test)\n",
    "model_df = model.transform(feat_test)\n",
    "\n",
    "# model_df.write().overwrite().save('s3a://kagglespotify6k/models/mile_6_model/mile_6_model_cos_sim/')\n",
    "\n",
    "##########################################\n",
    "\n",
    "# Run 1(30k): 26.94 seconds\n",
    "# Run 2(100k): 23.79 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099ac74-2055-47e8-b1e4-686f1a22e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced: https://stackoverflow.com/questions/34121258/cosine-similarity-via-dimsum-in-spark\n",
    "# https://spark.apache.org/docs/1.2.2/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html\n",
    "# https://stackoverflow.com/questions/57530010/spark-scala-cosine-similarity-matrix\n",
    "\n",
    "# model_df = spark.read.parquet('s3a://kagglespotify6k/models/mile_6_model/mile_6_model_cos_sim/')\n",
    "fin_feat = model_df.select('name','track_uri','artists_names', 'artists_genres', 'playlist_uris_list','features')\n",
    "fin_feat.cache()\n",
    "\n",
    "# Unique numeric index because number easier to manipulate than string identifier\n",
    "simfeat_test = fin_feat.withColumn(\"index\", monotonically_increasing_id())\n",
    "\n",
    "# Convert the vectors\n",
    "def row_to_vec(row):\n",
    "    row_vec = Vectors.sparse(row['features'].size, row['features'].indices, row['features'].values)\n",
    "    return IndexedRow(row['index'], row_vec)\n",
    "\n",
    "# RDD for spark\n",
    "indexed_rows = simfeat_test.rdd.map(row_to_vec)\n",
    "\n",
    "# Create an IndexedRowMatrix\n",
    "matrix = IndexedRowMatrix(indexed_rows)\n",
    "\n",
    "# Compute similarity with DIMSUM\n",
    "matrix_cos = matrix.toRowMatrix().columnSimilarities()\n",
    "\n",
    "# Convert to DataFrame\n",
    "sim_df1 = matrix_cos.entries.map(lambda e: (e.i, e.j, e.value)).toDF(['index1', 'index2', 'similarity'])\n",
    "\n",
    "sim_df2 = sim_df1.join(simfeat_test.select('index', 'track_uri', 'name', 'artists_names'), sim_df1.index2 == simfeat_test.index, 'left')\\\n",
    "    .withColumnRenamed('track_uri', 'rec_track_uri').withColumnRenamed('name', 'rec_song').withColumnRenamed('artists_names', 'rec_artists').drop('index')\\\n",
    "    .join(simfeat_test.select('index', 'track_uri', 'name', 'artists_names'),sim_df1.index1 == simfeat_test.index, 'left')\\\n",
    "    .withColumnRenamed('track_uri', 'orig_track_uri').withColumnRenamed('name', 'orig_song').withColumnRenamed('aritsts_names', 'orig_artists').drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a4978-79e9-4d3f-b240-fa8b973d8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_rec_m2(track_uri, num_rec,sim_df):\n",
    "    fin_rec = sim_df.filter((sim_df['orig_track_uri'] == track_uri) & (sim_df['rec_track_uri'] != track_uri)).orderBy(col(\"similarity\").desc()).limit(num_rec)\n",
    "    songs = fin_rec.collect()\n",
    "    print(f'Original Song: {songs[0][\"orig_song\"]} by {songs[0][\"artists_names\"]}')\n",
    "    for num, row in enumerate(songs, start = 1):\n",
    "        print(f\"{num}) {row['rec_song']} by {row['artists_names']}, Score: {row['similarity']}\")\n",
    "\n",
    "\n",
    "song_rec_m2('008wXvCVu8W8vCbq5VQDlC', 10, sim_df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song_dev-kernel",
   "language": "python",
   "name": "song_dev-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
