{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "42a6d297-58df-4b79-b00d-8a91b3e65ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import textwrap\n",
    "import time\n",
    "# from fuzzywuzzy import process\n",
    "from rapidfuzz import process, utils, fuzz\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166b822f-19f7-452d-8614-77d8221de572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'uri', 'duration_ms', 'time_signature', 'name', 'album_name',\n",
       "       'album_uri', 'artists'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_df = pd.read_csv('data/feat_df.csv')\n",
    "feat_df.columns\n",
    "# song_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebcff0-7f75-418d-88b8-01a7775bacd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vibes\n",
    "#  'danceability', 'energy', 'liveness', 'valence'\n",
    "\n",
    "# Music technicals\n",
    "#  -> Measure - continous\n",
    "#      'loudness', 'tempo'\n",
    "#  -> Measure - categorical\n",
    "#      'key', 'mode', 'time_signature'\n",
    "#  -> Instrumentality\n",
    "#      'speechiness', 'acousticness', 'instrumentalness'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd5d74-4a58-4f69-b61e-fbb0f654f7cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d7b69-3a3b-4895-aef0-4193759362e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 2, cols = 2, subplot_titles = ('danceability', 'energy', 'liveness', 'valence'), vertical_spacing = 0.1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = song_feats.danceability, name = 'daceability'), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.energy, name = 'energy'), row = 1, col = 2)\n",
    "fig.add_trace(go.Histogram(x = song_feats.liveness, name = 'liveness'), row = 2, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.valence, name = 'valence'), row = 2, col = 2)\n",
    "\n",
    "fig.update_layout(height = 850, width = 1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8f213-a2ac-45d8-b381-7c1a5959cc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 1, cols = 2, subplot_titles = ('loudness', 'tempo'), vertical_spacing = 0.1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = song_feats.loudness, name = 'loudness'), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.tempo, name = 'tempo'), row = 1, col = 2)\n",
    "\n",
    "fig.update_layout(height = 500, width = 1200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337bea3-ecd1-413f-a41a-f65d6639b6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 1, cols = 2, subplot_titles = ('key', 'mode'), vertical_spacing = 0.1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = song_feats.key, name = 'key'), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats['mode'], name = 'mode'), row = 1, col = 2)\n",
    "\n",
    "fig.update_layout(height = 500, width = 1200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07220adc-a566-49f8-a3cf-a17f05c6ad89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 3, cols = 1, subplot_titles = ('speechiness', 'acousticness', 'instrumentalness'), vertical_spacing = 0.1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x = song_feats.speechiness, name = 'key'), row = 1, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.acousticness, name = 'mode'), row = 2, col = 1)\n",
    "fig.add_trace(go.Histogram(x = song_feats.instrumentalness, name = 'key'), row = 3, col = 1)\n",
    "\n",
    "fig.update_layout(height = 850, width = 600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26594956-d47d-4c92-9eff-0b8142389c90",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03080f91-90b6-46cf-b927-171322736751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vibes\n",
    "#  'danceability', 'energy', 'liveness', 'valence'\n",
    "\n",
    "# Music technicals\n",
    "#  -> Measure - continous\n",
    "#      'loudness', 'tempo'\n",
    "#  -> Measure - categorical\n",
    "#      'key', 'mode', 'time_signature'\n",
    "#  -> Instrumentality\n",
    "#      'speechiness', 'acousticness', 'instrumentalness'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abc22a-aa26-46f6-9c7b-6823376f295e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Genre Feature\n",
    "* Extract the artist_uris present on track and find matching genres from the artist_info data\n",
    "    * Don't really need to artist name because you just need unique ID to do the search and match\n",
    "* Possible feature: Primary artist\n",
    "    * The \"primary artist\" or main artist in tracks with multiple artists\n",
    "    * This is to possibly put heavier weights on the primary artist's genres as the featured artist should not affect the general vibe of the song as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c616eb-80c8-4320-bf41-6a91b0473d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artist_df = pd.read_csv('data/artist_info.csv')\n",
    "album_tracks = pd.read_csv('data/album_tracks.csv')\n",
    "album_df = pd.read_csv('data/album_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df672008-55cd-4810-8f29-b2627dbe17d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# artist_df['genres'].apply(ast.literal_eval)\n",
    "artist_df['genres'] = artist_df['genres'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36f38bba-de2c-40a5-8997-2424af76ddc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.65678858757019 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Get the artist_uris from\n",
    "\n",
    "def extract_artist_uris(artist_raw):\n",
    "    try:\n",
    "        artist_liteval = ast.literal_eval(artist_raw)\n",
    "        artist_list = [artist['uri'] for artist in artist_liteval]\n",
    "        return(artist_list)\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "\n",
    "feat_df['artists_clean'] = feat_df['artists'].apply(extract_artist_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "6545ade5-2c66-4b17-907f-d4af2541bcde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_artist_name(artist_raw):\n",
    "    if isinstance(artist_raw, str):\n",
    "        artist_liteval = ast.literal_eval(artist_raw)\n",
    "    else:\n",
    "        artist_liteval = ast.literal_eval(artist_raw.item())\n",
    "    artist_list = [artist['name'] for artist in artist_liteval]\n",
    "    return artist_list\n",
    "\n",
    "# Applied to the raw JSON artists result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eee2943-bfa2-424a-ba7b-577515cac571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 95.94767260551453 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# getting the genres from artist into features\n",
    "\n",
    "def get_genres(uri_list):\n",
    "    try:\n",
    "        all_genres = []\n",
    "        for artist in uri_list:\n",
    "            genre_series = artist_df['genres'].loc[artist_df['artist_uri'] == artist]\n",
    "            for genre in genre_series:\n",
    "                all_genres.extend(genre)\n",
    "        return(all_genres)\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "feat_df['genres'] = feat_df['artists_clean'].apply(lambda x: get_genres(x))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac11875-9d06-4be1-90e2-2bc4a2f90e3c",
   "metadata": {},
   "source": [
    "## Feature Scaling and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "5f1a7f37-ae0c-4b14-ba73-94ec8422b28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating copy of dataframe\n",
    "feats_1 = feat_df.copy()\n",
    "feats_2 = feat_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "3fbd5957-8740-467b-a47c-baead4eaf375",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Scaling the song attribute measures\n",
    "scaled_vectors = min_max_scaler.fit_transform(feat_df[['loudness', 'tempo']])\n",
    "feats_1[['loudness_scaled', 'tempo_scaled']] = scaled_vectors\n",
    "feats_2[['loudness_scaled', 'tempo_scaled']] = scaled_vectors\n",
    "\n",
    "# Scaling instrumentality features\n",
    "instr_vectors = min_max_scaler.fit_transform(feat_df[['speechiness', 'acousticness', 'instrumentalness']])\n",
    "feats_1[['speechiness_scaled', 'acousticness_scaled', 'instrumentalness_scaled']] = instr_vectors\n",
    "feats_2[['speechiness_scaled', 'acousticness_scaled', 'instrumentalness_scaled']] = instr_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "07b5647d-790b-46ef-ba6e-c09339681996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the categorical data\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Song attributes\n",
    "feats_1 = pd.get_dummies(feats_1, columns = ['key', 'mode', 'time_signature'])\n",
    "feats_1.drop(columns = ['name', 'album_name', 'album_uri', 'artists', 'artists_clean', 'genres'], inplace = True)\n",
    "feats_2.drop(columns = ['name', 'album_name', 'album_uri', 'artists', 'artists_clean', 'genres'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687ad2d6-1a0c-4eba-9084-118b98e32616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vibes vector\n",
    "#  Note sure if needed\n",
    "feats_1['vibe_vector'] = feats_1[['danceability', 'energy', 'valence', 'liveness']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "32b861d4-cb89-4dcd-9a44-502e25fbb9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating genre matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_vectors = mlb.fit_transform(feat_df['genres'])\n",
    "genre_df = pd.DataFrame(genre_vectors, columns = mlb.classes_)\n",
    "genre_feat = pd.concat([feat_df.uri, genre_df], axis = 1)\n",
    "genre_feat = genre_feat.set_index('uri')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593fe23-0218-4988-baba-60569beace6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# V2: Cosine Similarity (sklearn implementation)\n",
    "* sklearn vs scipy vs creating your own with a function\n",
    "    * sklearn's is a vectorized function\n",
    "    * scipy seems to run it through a couple for loops (https://stackoverflow.com/questions/61490351/scipy-cosine-similarity-vs-sklearn-cosine-similarity)\n",
    "    * creating your own function then .apply() or something may be the only way if you need to do it in cloud computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d08c5f-3cf5-47c7-b913-58ce4623a7d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1ad1a-872a-4d01-b44f-ba2a5f6ebd5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Genre: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "e7a7c080-7aab-41be-93c4-70bcb68865f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using PCA reduction\n",
    "\n",
    "def pca_reduce_genre(df, n_comp):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pca = PCA(n_components = n_comp)\n",
    "    genre_feat_PCA = pd.DataFrame(pca.fit_transform(df), index = df.index)\n",
    "\n",
    "    print(\"pca_reduce_genre: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    return(genre_feat_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "3554feef-9052-4b91-980b-e6b8522f8e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To be used on PCA reduced data\n",
    "# Using the genre feature to reduce the overall amount of songs used in cosine similarity\n",
    "#  When trying to find similarity, makes sense to reccomend like-genre songs like Rock to Rock or K-pop to K-pop\n",
    "\n",
    "def batch_cosine_genre(df, uri):\n",
    "    all_start_time = time.time()\n",
    "    \n",
    "    uri_slice = df.loc[df.index == uri]\n",
    "    df_other = df.loc[~(df.index == uri)]\n",
    "    \n",
    "    top_res = []\n",
    "    \n",
    "    batch_size = 15000\n",
    "    num_batches = len(df_other) // batch_size + (1 if len(df_other) % batch_size != 0 else 0)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_time = time.time()\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch = df_other[start:end]\n",
    "        batch = pd.concat([batch, uri_slice])\n",
    "        \n",
    "        batch_cs = cosine_similarity(batch)\n",
    "        batch_cs_df = pd.DataFrame(batch_cs, index = batch.index)\n",
    "        index_pos = batch_cs_df.index.get_loc(uri_slice.index[0])\n",
    "        batch_sim_scores = batch_cs_df.iloc[:, index_pos]\n",
    "        batch_top_1000 = batch_sim_scores.nlargest(1000).index\n",
    "        top_res.append(batch_top_1000)\n",
    "        print(f\"Batch {i} time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "        # time.sleep(0.1)\n",
    "    \n",
    "    # Length of top_res is not actually (num_batches * 1000) because there are duplicated values of the uri_slice in each batch\n",
    "    #  so (num_batches * 1000) - (num_batches)\n",
    "    top_res_list = [item for sublist in top_res for item in sublist]\n",
    "    # top_res_select = df_other[df_other.index.isin(top_res_list)]\n",
    "    print(' COMPLETED')\n",
    "    print(\"batch_cosine_genre: --- %s seconds ---\" % (time.time() - all_start_time))\n",
    "    return(top_res_list)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "2ed19021-0d2f-4130-b5f4-e6b7f8df46c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Goes back to the feature dataframe and performs cosine\n",
    "def get_rec(df, tracks_df, uri, uri_list, top_n):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df_select = df[df.uri.isin(uri_list)]\n",
    "    df_select = df_select.set_index('uri')\n",
    "    # df_select = df_select.drop(columns = ['genres', 'vibe_vector']) # ad hoc\n",
    "\n",
    "    if len(uri_list) < 15000:\n",
    "        cs_res = cosine_similarity(df_select)\n",
    "        cs_res = pd.DataFrame(cs_res, index = df_select.index)\n",
    "        recs_raw =  cs_res[cs_res.index.get_loc(uri)].nlargest(top_n).index.to_list()\n",
    "        \n",
    "        target_slice = tracks_df[tracks_df.uri == uri]\n",
    "        recs_df = tracks_df[tracks_df.uri.isin(recs_raw)]\n",
    "        \n",
    "        print(textwrap.dedent(f\"\"\"\n",
    "        -------- Original Song --------\n",
    "        Song: {target_slice.name.item()}\n",
    "        Album: {target_slice.album_name.item()} \n",
    "        Artist(s): {extract_artist_name(target_slice.artists)}\n",
    "        -------------------------------\n",
    "        \"\"\"))\n",
    "        \n",
    "        for i in range(top_n):\n",
    "            if (recs_df.index[i] == target_slice.index):\n",
    "                pass\n",
    "            else:\n",
    "                print(textwrap.dedent(f\"\"\"\n",
    "                -------- Recommendation {i + 1} --------\n",
    "                Song: {recs_df.iloc[i]['name']}\n",
    "                Album: {recs_df.iloc[i]['album_name']}\n",
    "                Artist(s): {extract_artist_name(recs_df.iloc[i].artists)}\n",
    "                ----------------------------------\n",
    "                \"\"\"))\n",
    "#     else:\n",
    "#         uri_slice = df_select.loc[df_select.index == uri]\n",
    "#         df_other = df_select.loc[~(df_select.index == uri)]\n",
    "        \n",
    "#         batch_size = 15000\n",
    "#         num_batches = len(df_other) // batch_size + (1 if len(df_other) % batch_size != 0 else 0)\n",
    "    \n",
    "#         for i in range(num_batches):\n",
    "#             # start_time = time.time()\n",
    "#             start = i * batch_size\n",
    "#             end = start + batch_size\n",
    "#             batch = df_other[start:end]\n",
    "#             batch = pd.concat([batch, uri_slice])\n",
    "            \n",
    "#             batch_cs = cosine_similarity(batch)\n",
    "#             batch_cs = cosine_similarity(batch)\n",
    "#             batch_cs_df = pd.DataFrame(batch_cs, index = batch.index)\n",
    "#             index_pos = batch_cs_df.index.get_loc(uri_slice.index[0])\n",
    "#             batch_sim_scores = batch_cs_df.iloc[:, index_pos]\n",
    "    print(\"get_rec: --- %s seconds ---\" % (time.time() - start_time))           \n",
    "    return(recs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "3aead2b2-b56f-4b6c-908c-1d5810a0611c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the song name:  Butter\n",
      "Enter the artist name:  BTS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Is this the song you were looking for?\n",
      "    Song: Butter\n",
      "    Album: Proof\n",
      "    Artists: ['BTS']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input 'yes' or 'no':  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooray!\n",
      "Total time: --- 12.023147106170654 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def y_n_handler():\n",
    "    user_resp = input(\"Please input 'yes' or 'no': \")\n",
    "    \n",
    "    while True:\n",
    "        if user_resp in ['yes', 'no']:\n",
    "            return user_resp\n",
    "        else:\n",
    "            user_resp = input(\"Please input 'yes' or 'no': \")\n",
    "        \n",
    "\n",
    "def uri_lookup(df):\n",
    "    song_name = input(\"Enter the song name: \")\n",
    "    artist = input(\"Enter the artist name: \")\n",
    "    \n",
    "    df['song_artist_key'] = df.apply(lambda row: f\"{row['name']} - {row['artists_clean'][0]}\", axis=1)\n",
    "    df['matching_ratio'] = df.apply(lambda x: fuzz.ratio(x.song_artist_key, song_name + '-' + artist), axis=1).to_list()\n",
    "    df = df.sort_values('matching_ratio', ascending = False)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        print(textwrap.dedent(f\"\"\"\n",
    "        Is this the song you were looking for?\n",
    "            Song: {df.iloc[i]['name']}\n",
    "            Album: {df.iloc[i]['album_name']}\n",
    "            Artists: {df.iloc[i]['artists_clean']}\n",
    "        \"\"\"))\n",
    "        \n",
    "        resp = y_n_handler()\n",
    "        if resp == 'no':\n",
    "            continue\n",
    "        elif resp == 'yes':\n",
    "            # print('Hooray!')\n",
    "            return(df.iloc[i]['uri'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# start_time = time.time()\n",
    "# test2 = uri_lookup(album_tracks)\n",
    "# test2\n",
    "\n",
    "# print(\"Total time: --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "94f605e1-6e03-44db-a353-ec9224508d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the song name:  Radioactive\n",
      "Enter the artist name:  Imagine Dragons\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_match time: --- 0.8432800769805908 seconds ---\n",
      "artist_match time: --- 11.669719219207764 seconds ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[805], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 3\u001b[0m test_uri \u001b[38;5;241m=\u001b[39m \u001b[43muri_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43malbum_tracks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m test_genre_feat \u001b[38;5;241m=\u001b[39m pca_reduce_genre(genre_feat, \u001b[38;5;241m750\u001b[39m)\n\u001b[0;32m      5\u001b[0m func_test_set \u001b[38;5;241m=\u001b[39m test_genre_feat\n",
      "Cell \u001b[1;32mIn[753], line 24\u001b[0m, in \u001b[0;36muri_lookup\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(artist_match, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(artist_match) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     23\u001b[0m     artist, artist_score \u001b[38;5;241m=\u001b[39m artist_match[\u001b[38;5;241m0\u001b[39m], artist_match[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m     match \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m song) \u001b[38;5;241m&\u001b[39m (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martists\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43martist\u001b[49m\u001b[43m)\u001b[49m)]\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     26\u001b[0m         combined_score \u001b[38;5;241m=\u001b[39m (song_score \u001b[38;5;241m+\u001b[39m artist_score) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[753], line 24\u001b[0m, in \u001b[0;36muri_lookup.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(artist_match, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(artist_match) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     23\u001b[0m     artist, artist_score \u001b[38;5;241m=\u001b[39m artist_match[\u001b[38;5;241m0\u001b[39m], artist_match[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m     match \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m song) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martists\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m artist))]\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     26\u001b[0m         combined_score \u001b[38;5;241m=\u001b[39m (song_score \u001b[38;5;241m+\u001b[39m artist_score) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mC:\\Coding\\IDE\\Anaconda\\envs\\song_dev\\lib\\ast.py:64\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03mEvaluate an expression node or a string containing only a Python\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03mexpression.  The string or node provided may only consist of the following\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mCaution: A complex expression can overflow the C stack and cause a crash.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_or_string, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 64\u001b[0m     node_or_string \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_or_string, Expression):\n\u001b[0;32m     66\u001b[0m     node_or_string \u001b[38;5;241m=\u001b[39m node_or_string\u001b[38;5;241m.\u001b[39mbody\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_uri = uri_lookup(album_tracks)\n",
    "test_genre_feat = pca_reduce_genre(genre_feat, 500)\n",
    "func_test_set = test_genre_feat\n",
    "test_rec_set = batch_cosine_genre(func_test_set, test_uri)\n",
    "test_recs = get_rec(feats_2, album_tracks, test_uri, test_rec_set, 10)\n",
    "\n",
    "print(\"Total time: --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2fab1cf1-fc50-4535-991b-6438b0ce861b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23b16c2b-f5d8-48fc-b8d4-5316455c7759",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# (Deprecated) V1: AWS, Spark, and DIMSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844be12-c7ae-4f71-9440-e89fdda7887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Credentials and Settings\n",
    "access_key = 'ACCESS_KEY'\n",
    "secret_key = 'SECRET_ACCESS_KEY'\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = access_key\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = secret_key\n",
    "encoded_secret_key = secret_key.replace(\"/\", \"%2F\").replace(\"+\", \"%2B\")\n",
    "\n",
    "aws_region = 'us-east-1'\n",
    "\n",
    "s3 = boto3.client(\n",
    "    service_name='s3',\n",
    "    region_name=aws_region,\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86126180-1dc8-44b4-ad30-930095e77026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession, Row, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf, explode, col, collect_list, regexp_replace, split, expr, length, concat_ws, count, size, first, broadcast, monotonically_increasing_id\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType, FloatType, DoubleType\n",
    "from pyspark import sql\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Set up Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PicklesPlus\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", secret_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\",\"s3.\" + aws_region + \".amazonaws.com\") \\\n",
    "    .config(\"spark.executor.memory\", \"15g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.default.parallelism\", \"4\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a90c2b-fd72-401d-a5f6-a267aa065912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ML libraries\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "from pyspark.ml.stat import Correlation, ChiSquareTest, Summarizer\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, Tokenizer, HashingTF, IDF, VectorAssembler, StandardScaler, OneHotEncoder, Normalizer, StopWordsRemover, CountVectorizer\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors, VectorUDT\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7940b-6cbc-428f-9a72-de7c2c64482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = spark.read.parquet('s3a://kagglespotify6k/raw/main_dataset.parquet/')\n",
    "\n",
    "all_tracks = spark.read.parquet('s3a://kagglespotify6k/trusted/all_tracks/')\n",
    "\n",
    "\n",
    "# main contains some duplicate columns\n",
    "columns_to_drop = ['key', 'loudness', 'mode', 'tempo', 'time_signature']\n",
    "main_merge = main.drop(*columns_to_drop)\n",
    "\n",
    "# Join the 2 dataframes\n",
    "merged_df = all_tracks.join(main_merge, all_tracks['track_uri'] == main_merge['track_uri'])\n",
    "merged_df = merged_df.drop(main_merge['track_uri'])\n",
    "merged_df = merged_df.withColumn('playlist_uris', expr(\"substring(split(playlist_uris, ':')[2], 1, length(split(playlist_uris, ':')[2]) - 2)\"))\n",
    "merged_df = merged_df.withColumn('playlist_uris_list', split('playlist_uris', ',\\s'))\n",
    "\n",
    "merged_df.write.mode('overwrite').parquet('s3a://kagglespotify6k/trusted/merged_main_tracks_all/')\n",
    "\n",
    "# 28.79 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea3b99-c95a-4d01-ab92-1f9d7377d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df2 = spark.read.parquet('s3a://kagglespotify6k/trusted/feature_df_all270k/')\n",
    "\n",
    "# Aggregating the categorical features to avoid having to one hot encode with a for loop\n",
    "feat_df2 = feat_df2.withColumn('categorical', F.array(col('key'),col('mode'), col('time_signature')))\n",
    "feat_test = feat_df2.limit(900)\n",
    "## First, vectorize the textual categorical features (genre and playlists) into genre_vec\n",
    "\n",
    "# artists_genres & playlist_uris_list already tokenized -> [genre_a, genre_b, genre_c], skip straight to hashing\n",
    "hashingTF_genres = HashingTF(numFeatures = 50, inputCol = 'artists_genres', outputCol = 'genre_hash')\n",
    "idf_genres = IDF(inputCol = 'genre_hash', outputCol = 'genre_idf')\n",
    "\n",
    "hashingTF_playlists = HashingTF(numFeatures = 50, inputCol = 'playlist_uris_list', outputCol = 'playlist_hash')\n",
    "idf_playlists = IDF(inputCol = 'playlist_hash', outputCol = 'playlist_idf')\n",
    "\n",
    "## Vectorizing the music technique categorical features (key, mode, time_signature)\n",
    "# Referenced: https://stackoverflow.com/questions/35804755/apply-onehotencoder-for-several-categorical-columns-in-sparkmlib\n",
    "#   StringIndexer only takes in 1 column at a time\n",
    "hashingTF_categ = HashingTF(numFeatures = 50, inputCol = 'categorical', outputCol = 'categ_hash')\n",
    "idf_categ = IDF(inputCol = 'categ_hash', outputCol = 'categ_idf')\n",
    "\n",
    "## Vectorizing the confidence measure features (they are on a scale of 0 - 1.0)\n",
    "conf_VecAssembler = VectorAssembler(inputCols = ['acousticness', 'instrumentalness', 'speechiness', 'valence', 'danceability', 'energy', 'liveness'], outputCol = 'conf_features')\n",
    "# conf_scaler = StandardScaler(inputCol = 'conf_features', outputCol = 'scaled_conf_features')\n",
    "\n",
    "## Final feature vector\n",
    "final_VecAssembler = VectorAssembler(inputCols=['genre_idf', 'playlist_idf', 'categ_idf', 'conf_features'], outputCol='features')\n",
    "\n",
    "## Pipeline\n",
    "pipeline = Pipeline(stages = [hashingTF_genres, idf_genres, hashingTF_playlists, idf_playlists , hashingTF_categ, idf_categ, conf_VecAssembler, final_VecAssembler])\n",
    "\n",
    "model = pipeline.fit(feat_test)\n",
    "model_df = model.transform(feat_test)\n",
    "\n",
    "# model_df.write().overwrite().save('s3a://kagglespotify6k/models/mile_6_model/mile_6_model_cos_sim/')\n",
    "\n",
    "##########################################\n",
    "\n",
    "# Run 1(30k): 26.94 seconds\n",
    "# Run 2(100k): 23.79 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099ac74-2055-47e8-b1e4-686f1a22e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced: https://stackoverflow.com/questions/34121258/cosine-similarity-via-dimsum-in-spark\n",
    "# https://spark.apache.org/docs/1.2.2/api/java/org/apache/spark/mllib/linalg/distributed/RowMatrix.html\n",
    "# https://stackoverflow.com/questions/57530010/spark-scala-cosine-similarity-matrix\n",
    "\n",
    "# model_df = spark.read.parquet('s3a://kagglespotify6k/models/mile_6_model/mile_6_model_cos_sim/')\n",
    "fin_feat = model_df.select('name','track_uri','artists_names', 'artists_genres', 'playlist_uris_list','features')\n",
    "fin_feat.cache()\n",
    "\n",
    "# Unique numeric index because number easier to manipulate than string identifier\n",
    "simfeat_test = fin_feat.withColumn(\"index\", monotonically_increasing_id())\n",
    "\n",
    "# Convert the vectors\n",
    "def row_to_vec(row):\n",
    "    row_vec = Vectors.sparse(row['features'].size, row['features'].indices, row['features'].values)\n",
    "    return IndexedRow(row['index'], row_vec)\n",
    "\n",
    "# RDD for spark\n",
    "indexed_rows = simfeat_test.rdd.map(row_to_vec)\n",
    "\n",
    "# Create an IndexedRowMatrix\n",
    "matrix = IndexedRowMatrix(indexed_rows)\n",
    "\n",
    "# Compute similarity with DIMSUM\n",
    "matrix_cos = matrix.toRowMatrix().columnSimilarities()\n",
    "\n",
    "# Convert to DataFrame\n",
    "sim_df1 = matrix_cos.entries.map(lambda e: (e.i, e.j, e.value)).toDF(['index1', 'index2', 'similarity'])\n",
    "\n",
    "sim_df2 = sim_df1.join(simfeat_test.select('index', 'track_uri', 'name', 'artists_names'), sim_df1.index2 == simfeat_test.index, 'left')\\\n",
    "    .withColumnRenamed('track_uri', 'rec_track_uri').withColumnRenamed('name', 'rec_song').withColumnRenamed('artists_names', 'rec_artists').drop('index')\\\n",
    "    .join(simfeat_test.select('index', 'track_uri', 'name', 'artists_names'),sim_df1.index1 == simfeat_test.index, 'left')\\\n",
    "    .withColumnRenamed('track_uri', 'orig_track_uri').withColumnRenamed('name', 'orig_song').withColumnRenamed('aritsts_names', 'orig_artists').drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a4978-79e9-4d3f-b240-fa8b973d8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_rec_m2(track_uri, num_rec,sim_df):\n",
    "    fin_rec = sim_df.filter((sim_df['orig_track_uri'] == track_uri) & (sim_df['rec_track_uri'] != track_uri)).orderBy(col(\"similarity\").desc()).limit(num_rec)\n",
    "    songs = fin_rec.collect()\n",
    "    print(f'Original Song: {songs[0][\"orig_song\"]} by {songs[0][\"artists_names\"]}')\n",
    "    for num, row in enumerate(songs, start = 1):\n",
    "        print(f\"{num}) {row['rec_song']} by {row['artists_names']}, Score: {row['similarity']}\")\n",
    "\n",
    "\n",
    "song_rec_m2('008wXvCVu8W8vCbq5VQDlC', 10, sim_df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song_dev-kernel",
   "language": "python",
   "name": "song_dev-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
